{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2237c5d-c458-4329-8188-381285596c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mplPath\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import h5py, json\n",
    "from osgeo import ogr\n",
    "\n",
    "from pyproj import Proj\n",
    "proj_stere = Proj('epsg:3031')\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b75c0-9aab-465d-979d-4c6fa1983dcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Load the bed pick dataframe ###\n",
    "\n",
    "df = pd.read_csv('../../proc/Picked_Bed_Power.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c84f99-95f3-4d0c-887f-640d5291df13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Filter the dataset to Whillans Ice Plain only ###\n",
    "\n",
    "# All flight days\n",
    "fdays = np.sort(df['Flight Day'].unique())\n",
    "\n",
    "# Kamb flight days\n",
    "kamb_days = fdays[[1,3,4,7]]  #4\n",
    "# Whillans flight days\n",
    "whillans_days = np.delete(fdays,[1,3,4,7])\n",
    "\n",
    "# Separate dataframes\n",
    "kamb_df = df[df['Flight Day'].isin(kamb_days)]\n",
    "df = df[df['Flight Day'].isin(whillans_days)]\n",
    "# Add in a single frame from a kamb day where part of the flight was over SLW\n",
    "df = pd.concat([df, kamb_df[(kamb_df['Flight Day']==20131227) & (kamb_df['Segment'] == 12)]])\n",
    "whillans_days = np.append(whillans_days,20131227)\n",
    "\n",
    "# Subset Whillans dataframe by y coordinate\n",
    "df = df[df['Y'] > -1e6]\n",
    "df = df[df['Y'] < -.48e6]\n",
    "\n",
    "# Remove traces with large aircraft pitch or roll\n",
    "df = df[abs(df['Roll']) < 0.1]\n",
    "df = df[abs(df['Pitch']) < 0.075]\n",
    "\n",
    "# Empty array for adjusted bed power\n",
    "df['P_bed_adj'] = df['P_bed'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def22ad-f3f4-4dd5-8be3-a1ba9d0d2167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot to check that the days are correct\n",
    "plt.figure(figsize=(4,3))\n",
    "ax = plt.subplot(111)\n",
    "kamb_df.plot.scatter(ax=ax,x='X',y='Y',c='lightblue',s=1)\n",
    "df.plot.scatter(ax=ax,x='X',y='Y',c='b',s=1)\n",
    "ax.axis('equal')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c520908-d351-4f2a-9f5a-a0c49d9721e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### A function to level the power at crossover points ###\n",
    "\n",
    "def crossover_leveling(df,cal_variable,days,days_to_add,crossover_dist=100,print_num=5000,verbose=False):\n",
    "    \n",
    "    # Separate into two dataframes, 1st the 'true' power and 2nd to adjust\n",
    "    idxs1 = df['Flight Day'].isin(days)\n",
    "    idxs2 = df['Flight Day'].isin(days_to_add)\n",
    "    df1 = df.loc[idxs1]\n",
    "    df2 = df.loc[idxs2]\n",
    "    \n",
    "    # Empty array for power differences at crossovers\n",
    "    dP = np.array([])\n",
    "    \n",
    "    # Loop through every trace in the 2nd dataframe\n",
    "    for i,idx in enumerate(df2.index):\n",
    "        if i%print_num==0 and verbose:\n",
    "            print(round(i/len(df2),3)*100,'% finished...')\n",
    "            print('Total crossover traces added:',len(dP))\n",
    "        # Get the distance from the selected trace to every trace in df1\n",
    "        dist = np.sqrt((df2.loc[idx,'X']-df1['X'])**2.+(df2.loc[idx,'Y']-df1['Y'])**2.)\n",
    "        # Add the power difference for \n",
    "        dP = np.append(dP,df1[cal_variable][dist<crossover_dist] - df2.loc[idx,cal_variable])\n",
    "\n",
    "    # Adjust the power for the added days\n",
    "    df.loc[idxs2,'P_bed_adj'] = df.loc[idxs2,'P_bed'] + np.nanmean(dP)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Power adjusted by:\",np.nanmean(dP),' for days:',days_to_add)\n",
    "        \n",
    "    return df, dP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9b2e77-33e2-41c3-9d04-215f902f8813",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Do the crossover power adjustment for each day ###\n",
    "\n",
    "# Add days in a specific order to maximize crossover points\n",
    "day_order = [20131219, 20131223, 20140108, 20140104, 20140109, 20131231, 20140111, 20131227, 20140102]\n",
    "\n",
    "# Initialize the figures and colors to plot for each day\n",
    "plt.figure()\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "for i in range(1,2):\n",
    "    # Do the adjustment for each day, using the function from the previous cell\n",
    "    print(\"Crossover Leveling Adjustment #\",i)\n",
    "    print(\"Control Days:\",np.delete(whillans_days,i))\n",
    "    print(\"Adjusted Days:\",whillans_days[i])\n",
    "    df, dP = crossover_leveling(df,'P_bed',np.delete(whillans_days,i),[whillans_days[i]],crossover_dist=50,print_num=10000,verbose=True)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Plot a histogram of power difference at crossover points\n",
    "    plt.hist(-dP,bins=len(dP)//100,color=colors[i],alpha=0.25)\n",
    "    plt.axvline(-np.nanmean(dP),color=colors[i])\n",
    "    \n",
    "plt.ylim(0,1000)\n",
    "plt.xlabel('Crossover Power (dB)')\n",
    "plt.ylabel('Number of Traces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc17e0-cdbb-462e-841a-fde5d2586a61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Do the crossover power adjustment for each day ###\n",
    "\n",
    "# Initialize the figures and colors to plot for each day\n",
    "plt.figure()\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "for i in range(1,9):\n",
    "    # Do the adjustment for each day, using the function from the previous cell\n",
    "    print(\"Crossover Leveling Adjustment #\",i)\n",
    "    print(\"Control Days:\",np.delete(whillans_days,i))\n",
    "    print(\"Adjusted Days:\",whillans_days[i])\n",
    "    df, dP = crossover_leveling(df,'P_surf',np.delete(whillans_days,i),[whillans_days[i]],crossover_dist=50,print_num=10000,verbose=True)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Plot a histogram of power difference at crossover points\n",
    "    plt.hist(-dP,bins=len(dP)//100,color=colors[i],alpha=0.25)\n",
    "    plt.axvline(-np.nanmean(dP),color=colors[i])\n",
    "    \n",
    "plt.ylim(0,1000)\n",
    "plt.xlabel('Crossover Power (dB)')\n",
    "plt.ylabel('Number of Traces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e056b43-cb49-4af4-b84e-35d4159c711e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Do the crossover power adjustment for each day ###\n",
    "\n",
    "df['P_surf_adj'] = df['P_surf'] + (df['P_bed_adj'] - df['P_bed'])\n",
    "\n",
    "# Initialize the figures and colors to plot for each day\n",
    "plt.figure()\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "for i in range(1):\n",
    "    # Do the adjustment for each day, using the function from the previous cell\n",
    "    print(\"Crossover Leveling Adjustment #\",i)\n",
    "    print(\"Control Days:\",np.delete(whillans_days,i))\n",
    "    print(\"Adjusted Days:\",whillans_days[i])\n",
    "    df, dP = crossover_leveling(df,'P_bed_adj',np.delete(whillans_days,i),[whillans_days[i]],crossover_dist=50,print_num=10000,verbose=True)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Plot a histogram of power difference at crossover points\n",
    "    plt.hist(-dP,bins=len(dP)//100,color=colors[i],alpha=0.25)\n",
    "    plt.axvline(-np.nanmean(dP),color=colors[i])\n",
    "    \n",
    "plt.ylim(0,1000)\n",
    "plt.xlabel('Crossover Power (dB)')\n",
    "plt.ylabel('Number of Traces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d44d344-02e3-4453-9cb7-6320a93523fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Recalculate the crossover power for the adjusted dataset, on all days ###\n",
    "### Make sure Surface Time is centered on 0 ###\n",
    "\n",
    "df_hold, dP = crossover_leveling(df,day_order[:4],day_order[4:],print_num=50000,verbose=True)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(dP,bins=200)\n",
    "plt.axvline(0,color='k')\n",
    "plt.title('After Adjustment')\n",
    "plt.xlabel('Crossover Power (dB)')\n",
    "plt.ylabel('Number of Traces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05225f46-689a-4bf4-a8d1-2c16bbc1aac2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "for i in range(9):\n",
    "    df[df['Flight Day']==whillans_days[i]].plot.scatter(ax=ax1,x='X',y='Y',c=colors[i],s=1,label=whillans_days[i])\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "bins = np.arange(-160,-70,0.1)\n",
    "plt.hist(df['P_bed_adj'],bins=bins,color='lightgrey');\n",
    "for i,day in enumerate(whillans_days):\n",
    "    plt.hist(df[df['Flight Day']==day]['P_bed_adj'],bins=bins,color=colors[i],label=day)\n",
    "plt.legend(title='Flight Day',fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5600edaa-49f3-47c2-90d0-b2815b4d09a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Calculate a relative reflectivity ###\n",
    "\n",
    "G = 20*np.log10(2.*(df['h'] + df['H']/np.sqrt(epsr_ice)))\n",
    "\n",
    "# Attenuation\n",
    "N = 10 # one-way rate (dB/km)\n",
    "L = 2.*N * df['H']/1000.\n",
    "\n",
    "# Reflectivity\n",
    "df['Relative Reflectivity'] = df['P_bed_adj'] + G + L\n",
    "# Move the mean to 0\n",
    "df['Relative Reflectivity'] -= df['Relative Reflectivity'].mean()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "\n",
    "ax1 = plt.subplot(111)\n",
    "df.plot.scatter(ax=ax1,x='X',y='Y',c='Relative Reflectivity',cmap='magma',s=1,vmin=-25,vmax=15)\n",
    "ax1.axis('equal')\n",
    "plt.xlim(-300000,-100000)\n",
    "plt.ylim(-800000,-500000)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c4b70c-68af-4ec2-8205-49174d524541",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Import InSAR grounding line and create a mask for traces grounded/floating ###\n",
    "\n",
    "file = ogr.Open(\"/Users/bhills/Drive/Research/Maps/antarctica/Outlines/5000001062176/128409163/GroundingLine_Antarctica_v02.shp\")\n",
    "shape = file.GetLayer(0)\n",
    "feature = shape.GetFeature(0) #first feature of the shapefile\n",
    "gls = json.loads(feature.ExportToJson())['geometry']['coordinates']\n",
    "gl_coords = np.empty((0,2))\n",
    "for gl in gls:\n",
    "    gl_coords = np.append(gl_coords,gl[0],axis=0)\n",
    "    \n",
    "start = 35000\n",
    "end = 38000\n",
    "gl_crop = gl_coords[start:end]\n",
    "gl_crop = np.append(gl_crop,np.array([[-1000000,0],[1000000,0],gl_crop[0]]),axis=0)\n",
    "\n",
    "gl_Path = mplPath.Path(np.transpose([gl_crop[:,0],gl_crop[:,1]]))\n",
    "df['Grounded'] = gl_Path.contains_points(df[['X','Y']]).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e93100b-16a3-4cb1-962a-9857a878b460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Import lake outlines and create a mask for traces lake/not-lake ###\n",
    "\n",
    "# Subglacial lake outlines (Siegfried & Fricker, 2018)\n",
    "lakes = h5py.File('../../data/outlines/SiegfriedFricker2018-outlines.h5', 'r')\n",
    "wh_lake_keys = ['EngelhardtSubglacialLake', 'WhillansSubglacialLake', 'Whillans_6', 'Whillans_7', 'Whillans_8','Lake78','Lake10']\n",
    "\n",
    "df['Lake'] = np.zeros_like(df['X']).astype(bool)\n",
    "\n",
    "for key in wh_lake_keys:\n",
    "    lake_x = np.squeeze(lakes[key]['x'][:])\n",
    "    lake_y = np.squeeze(lakes[key]['y'][:])\n",
    "    lake_Path = mplPath.Path(np.transpose([lake_x,lake_y]))\n",
    "    df[key] = lake_Path.contains_points(df[['X','Y']]).astype(bool)\n",
    "    df['Lake'] = np.logical_or(df['Lake'],df[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64492f18-1e7d-44d5-834f-95846a21c8b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,3))\n",
    "\n",
    "ax1 = plt.subplot(131)\n",
    "df[df['Grounded']==True].plot.scatter(ax=ax1,x='X',y='Y',c='Relative Reflectivity',cmap='magma',s=1,vmin=-25,vmax=15)\n",
    "plt.plot(gl_crop[:,0],gl_crop[:,1],'k-')\n",
    "ax1.axis('equal')\n",
    "plt.xlim(-300000,-100000)\n",
    "plt.ylim(-800000,-500000)\n",
    "\n",
    "ax2 = plt.subplot(132)\n",
    "df[df['Lake']==True].plot.scatter(ax=ax2,x='X',y='Y',c='Relative Reflectivity',cmap='magma',s=1,vmin=-25,vmax=15)\n",
    "plt.plot(gl_crop[:,0],gl_crop[:,1],'k-')\n",
    "ax2.axis('equal')\n",
    "plt.xlim(-300000,-100000)\n",
    "plt.ylim(-800000,-500000)\n",
    "\n",
    "ax3 = plt.subplot(133)\n",
    "df[df['Grounded']==False].plot.scatter(ax=ax3,x='X',y='Y',c='Relative Reflectivity',cmap='magma',s=1,vmin=-25,vmax=15)\n",
    "plt.plot(gl_crop[:,0],gl_crop[:,1],'k-')\n",
    "ax3.axis('equal')\n",
    "plt.xlim(-300000,-100000)\n",
    "plt.ylim(-800000,-500000)\n",
    "\n",
    "for key in lakes.keys():\n",
    "    lake_x = np.squeeze(lakes[key]['x'][:])\n",
    "    lake_y = np.squeeze(lakes[key]['y'][:])\n",
    "    for ax in [ax1,ax3]:\n",
    "        ax.plot(lake_x,lake_y,c='steelblue')\n",
    "        \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b4a502-fe85-4883-8d10-a8a5840f018c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('../../proc/Processed_Reflectivity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcccc3c-c4d5-4c06-b75f-63f0f2f24ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
